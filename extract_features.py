import re
import os
import sys
import json
import string
import datetime
import progressbar

from multiprocessing import Pool

"""Debug log switch"""
DEBUG = False
"""String length sensibility"""
N = 6
"""Printable characters set"""
printable = set(string.printable)
"""Times program turn 100"""
times = 0
"""Absolute DIR of the program"""
DIR = os.path.abspath(sys.argv[1])
"""Dictionary with all the features extracted"""
res = {}
"""Bar for status"""
bar = None
"""Getting parameters from command line"""
if len(sys.argv) > 2:
    outfile = os.path.abspath(sys.argv[2])
else:
    outfile = 'output.txt'
"""Open output file"""
out = open(outfile, 'w')

"""Element to contain extracted information"""
class element(object):
    def __init__(self,
                 absname,
                 fileasm,
                 filebytes):
        """File ID"""
        self.identifier = absname
        """Path to the disassembled file"""
        self.file_asm = fileasm
        """Path to the bytes file"""
        self.file_bytes = filebytes
        """File size"""
        self.file_size = 0
        """Strings inside the file"""
        self.file_strings = []
        """Program information"""
        self.pi = None

class program_information(object):
    def __init__(self):
        """BB Counter"""
        self.bb_count = 0
        """Program Sections"""
        self.sections = []
        """call count"""
        self.call_count = 0
        """mov count"""
        self.mov_count = 0
        """push count"""
        self.push_count = 0
        """pop count"""
        self.pop_count = 0
        """add count"""
        self.add_count = 0
        """sub count"""
        self.sub_count = 0
        """xor count"""
        self.xor_count = 0
        """jmp count (e.g. jmp, jz, je etc)"""
        self.jmp_count = 0

"""Get size of the bytes file"""
def get_size(path_to_file):
    return os.stat(path_to_file).st_size

"""Get program information from asm"""
def get_program_info(path_to_file):
    ps = program_information()
    with open(path_to_file) as file_:
        subs = set()
        sections = set()
        ps.mov_count = 0
        ps.push_count = 0
        ps.pop_count = 0
        ps.add_count = 0
        ps.sub_count = 0
        ps.xor_count = 0
        ps.jmp_count = 0

        for line in file_:
            """Getting subs"""
            m = re.search(r'sub_\w+', line)
            if m != None:
                subs.add(m.group(0))

            """Getting sections"""
            m = re.search(r'\.\w+:', line)
            if m != None:
                sections.add(m.group(0))

            """Getting call"""
            m = re.search(r'call ', line)
            if m != None:
                ps.call_count = ps.call_count + 1

            """Getting mov"""
            m = re.search(r'mov', line)
            if m != None:
                ps.mov_count = ps.mov_count + 1

            """Getting push"""
            m = re.search(r'push', line)
            if m != None:
                ps.push_count = ps.push_count + 1

            """Getting push"""
            m = re.search(r'push', line)
            if m != None:
                ps.pop_count = ps.pop_count + 1

            """Getting add"""
            m = re.search(r'add', line)
            if m != None:
                ps.add_count = ps.add_count + 1

            """Getting sub"""
            m = re.search(r'sub ',  line)
            if m != None:
                ps.sub_count = ps.sub_count + 1

            """Getting xor"""
            m = re.search(r'xor', line)
            if m != None:
                ps.xor_count = ps.xor_count + 1

            """Getting jmp"""
            m = re.search(r'j[a-zA-Z][a-zA-Z] ', line)
            if m != None:
                ps.jmp_count = ps.jmp_count + 1

    ps.bb_count = len(subs)
    ps.sections = list(sections)
    return ps

"""Get strings from bytes"""
def get_strings(path_to_file):
    el = []
    with open(path_to_file) as file_:
        for line in file_:
            hex_bytes = line.strip().split()[1:]
            try:
                raw_bytes = map(lambda h_str: h_str.decode('hex'), hex_bytes)
                printable_bytes = filter(lambda s: 32 < ord(s) < 127, raw_bytes)

                if len(printable_bytes) > N:
                    el.append("".join(printable_bytes))
            except:
                continue
    return el

"""Dump the data collected in json format"""
def dump_json(data):
    for key, el in data.iteritems():
        todump = {
                'id' : el.identifier,
                'asm_path' : el.file_asm,
                'bytes_path' : el.file_bytes,
                'file_string' : el.file_strings,
                'size' : el.file_size,
                'sections' : el.pi.sections,
                'bb': el.pi.bb_count,
                'call' : el.pi.call_count,
                'mov' : el.pi.mov_count,
                'push' : el.pi.push_count,
                'pop' : el.pi.pop_count,
                'add' : el.pi.add_count,
                'sub' : el.pi.sub_count,
                'xor' : el.pi.xor_count,
                'jmp' : el.pi.jmp_count,
                }
        json.dump(todump, out, indent=4, separators=(',',':'), ensure_ascii=False)

"""This function parallelize the feature extraction"""
def extract_features(absname, worker_id):
    obj = element(absname,
                  str(absname) + ".asm",
                  str(absname) + ".bytes")
    obj.file_size = get_size(os.path.join(DIR, obj.file_bytes))
    obj.pi = get_program_info(os.path.join(DIR, obj.file_asm))
    obj.file_strings = get_strings(os.path.join(DIR,obj.file_bytes))

    if DEBUG:
        print "Worker {}) {}: {}".format(worker_id, absname, obj)
    return (worker_id,{absname:obj})

def collect_results(r):
    global times
    global bar
    worker_id, r = r
    if DEBUG:
        print "Collecting results for worker {}".format(worker_id)

    bar.update(times)
    times = times + 1

    if (not(len(res.keys()) % 500)):
        if DEBUG:
            print "{}: Collected {}".format(datetime.datetime.utcnow(),
                                        len(res.keys())*times)
        dump_json(res)
        res.clear()
    res.update(r)

"""Pool for multiprocessing"""
pool = Pool(processes=32)

for root, dirs, filenames in os.walk(DIR):
    i = 0
    bar = progressbar.ProgressBar(max_value=len(filenames)/2)
    for f in filter(lambda x:x.endswith(".bytes"), filenames):
        absname = f.split('.')[0]
        pool.apply_async(extract_features, args=(absname,i,),
                                         callback=collect_results)
        i = i+1
    pool.close()
    pool.join()

    if DEBUG:
        print res
    dump_json(res)
    out.close()
