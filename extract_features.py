import re
import os
import sys
import json

from multiprocessing import Pool
# import psycopg2

# """Dictionary with all the extracted features"""
# data = {}

"""Debug log switch"""
DEBUG = False

"""Element to contain extracted information"""
class element(object):
    def __init__(self,
                 absname,
                 fileasm,
                 filebytes):
        """File ID"""
        self.identifier = absname
        """Path to the disassembled file"""
        self.file_asm = fileasm
        """Path to the bytes file"""
        self.file_bytes = filebytes
        """File size"""
        self.file_size = 0
        """Strings inside the file"""
        self.file_strings = []
        """Basic Block Counter"""
        self.file_bb = 0

"""Get size of the bytes file"""
def get_size(path_to_file):
    return os.stat(path_to_file).st_size

"""Get number of basic block"""
def get_bb_count(path_to_file):
    with open(path_to_file) as file_:
        subs = []
        for line in file_:
            m = re.search(r'sub_\w+',line)
            if m != None:
                # print m.group(0)
                subs.append(m.group(0))
    return len(set(subs))

"""Dump the data collected in json format"""
def dump_json(data, outfile):
    for key, el in data.iteritems():
        todump = {
                'id' : el.identifier,
                'asm_path' : el.file_asm,
                'bytes_path' : el.file_bytes,
                'file_string' : el.file_strings,
                'size' : el.file_size,
                'bb': el.file_bb,
                }
        json.dump(todump, outfile, indent=4, separators=(',',':'), ensure_ascii=False)

"""This function parallelize the feature extraction"""
def extract_features(absname, worker_id):
    obj = element(absname,
                  str(absname) + ".asm",
                  str(absname) + ".bytes")
    obj.file_size = get_size(os.path.join(DIR, obj.file_bytes))
    obj.file_bb = get_bb_count(os.path.join(DIR, obj.file_asm))

    if DEBUG:
        print "Worker {}) {}: {}".format(worker_id, absname, obj)
    return (worker_id,{absname:obj})

def collect_results(r):
    worker_id, r = r
    if DEBUG:
        print "Collecting results for worker {}".format(worker_id)

    if (not(len(res.keys()) % 1000)):
        print "Collected {}".format(len(res.keys()))
    res.update(r)

DIR = os.path.abspath(sys.argv[1])
pool = Pool(processes=32)
res = {}

if len(sys.argv) > 2:
    outfile = os.path.abspath(sys.argv[2])
else:
    outfile = 'output.txt'

for root, dirs, filenames in os.walk(DIR):
    data = {}
    out = open(outfile, 'w')
    i = 0
    for f in filter(lambda x:x.endswith(".bytes"), filenames):
        absname = f.split('.')[0]
        pool.apply_async(extract_features, args=(absname,i,),
                                         callback=collect_results)
        i = i+1
    pool.close()
    pool.join()

    print res
    dump_json(res, out)
    # print "{} {} {}".format(obj.identifier, obj.file_size, obj.file_bb)
    out.close()

# conn = psycopg2.connect("dbname=test user=postgres")
# cur = conn.cursor()
# cur.execute("CREATE TABLE test (id serial PRIMARY KEY, num )")
