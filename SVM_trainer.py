import os
import sys
import time
import json
import progressbar

from scipy.sparse import csr_matrix
from scipy.sparse import vstack
from scipy import io

from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.externals import joblib
from sklearn.model_selection import train_test_split

from multiprocessing import Pool
from multiprocessing import Lock

"""DEBUG print switch"""
DEBUG=False
"""absolute DIR of the program"""
DIR  = os.path.abspath(sys.argv[1])
"""Contains the dataset"""
matrix = csr_matrix([])
"""Status bar"""
bar = None
"""Counter for status bar"""
counter = 0
"""Features labels"""
y = []
"""Lock"""
lock = Lock()

"""Callback function"""
def update(r):
    global y
    global matrix
    global lock
    global counter
    vect, feat = r
    lock.acquire()
    y.append(feat)

    if matrix.getnnz() == 0:
        matrix = csr_matrix(vect)
    else:
        matrix = vstack([matrix,vect])
    counter += 1
    lock.release()
    bar.update(counter)

"""LoadJSON"""
def loadJSON(f, worker_id):
    with open (DIR+ "/" + f, "r") as fd:
        data = json.load(fd)
        y = data['family']

        """Deleting useless key"""
        del data['bytes_path']
        del data['family']
        del data['asm_path']
        del data['id']

    return (data.values(),y)

pool = Pool(processes=20)

def call_trainer(train, test):
    clf = svm.SVC(decision_function_shape='ovo')
    clf.fit()

"""Sfm trainer main function"""
def loadingData():
    global bar
    global matrix
    global y
    global pool

    i = 0
    for root, dirs, filenames in os.walk(DIR):
        for f in filter(lambda x:x.endswith(".json"), filenames):
            pool.apply_async(loadJSON,
                             args=(f,i,),
                             callback=update)
            i += 1
        bar = progressbar.ProgressBar(max_value=i)
        pool.close()
        pool.join()

    io.mmwrite('matrix.mtx', matrix)

    with open('list.mtx', 'w') as file_:
        for item in y:
            file_.write("{}\n".format(item))
"""Neural Net function"""
def rf_trainer(X_train, X_test, y_train, y_test):
    if os.path.isfile('rf_model.pkl'):
        rf = joblib.load('rf_model.pkl')
    # else:
        # rf =


"""SVM trainer function"""
def svm_trainer(X_train, X_test, y_train, y_test):
    if os.path.isfile('svm_model.pkl'):
        clf = joblib.load('svm_model.pkl')
    else:
        clf = svm.SVC(decision_function_shape ='ovo', probability = True)
        clf.fit(X_train, y_train)
        joblib.dump(clf, 'svm_model.pkl')

    i=0
    pos=0
    neg=0
    for row in X_test:
        res = clf.predict(row)
        if res == y_test[i]:
            pos += 1
        else:
            neg += 1
        i += 1
    print  'Tot: {} \nPos: {}\n Neg: {}'.format(pos+neg,pos, neg)

def trainer():
    global matrix
    global y
    if matrix.getnnz() == 0:
        matrix = io.mmread('matrix.mtx')

    if len(y) == 0:
        with open('list.mtx', 'r') as file_:
            for l in file_:
                y.append(int(l))

    X_train, X_test, y_train, y_test = train_test_split (matrix, y,
                                                         test_size=0.33,
                                                         random_state=55)
    svm_trainer(X_train, X_test, y_train, y_test)
    rf_trainer(X_train, X_test, y_train, y_test)
    if DEBUG:
        print "------X train ------\n"
        print X_train
        print type(X_train)
        print y_train
        print type(y_train)
        print "-------------------\n"
        print "------X test -------\n"
        print X_test
        print type(X_test)
        print y_test
        print type(y_test)
        print "-------------------\n"
        dens = matrix.todense()

        for i in range(0, len(y)):
            print "{} {}".format(y[i],dens.item((i,127522)))


if __name__ == "__main__":
    if not ((os.path.isfile('matrix.mtx') and os.path.isfile('list.mtx'))):
        loadingData()
    trainer()
