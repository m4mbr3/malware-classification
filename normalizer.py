import os
import sys
import json
import timeit
import progressbar

import numpy as np

from pprint import pprint

# from malclass import element
# from malclass import program_information

from sklearn import preprocessing
from sklearn.feature_extraction import DictVectorizer

"""Absolute DIR of the program"""
DIR = os.path.abspath(sys.argv[1])
DIR_NORM = DIR+"/../normalyzed"
try:
    os.makedirs(DIR_NORM)
except OSError:
    print 'Folder {} already created'.format(DIR_NORM)

"""Counter of file analyzed"""
counter = 0
"""Debug prints switch"""
DEBUG = False
"""Features"""
features = ["size","bb","family","call","mov","push","pop","add","sub","xor","jmp"]
"""Dataset matrix"""
matrix = None
"""Bar for status"""
bar = None

"""
JSON db loader
f: file descriptor from open
"""
def loadJSON(f):
    global matrix
    with open(DIR+"/"+f, "r") as fd:
        data = json.load(fd)
        x = [data['size'],
             data['bb'],
             # data['family'],
             data['call'],
             data['mov'],
             data['push'],
             data['pop'],
             data['add'],
             data['sub'],
             data['xor'],
             data['jmp']]

        if matrix == None:
            matrix = x
        else:
            if DEBUG:
                print "x = {}".format(x)
                print "Matrix \n\n {}".format(matrix)
            matrix = np.vstack([matrix, x])

"""
JSON db saver
f: file descriptor from open
"""
def storeJSON(f,i):
    global matrix
    with open(DIR+"/"+f, "r") as fd:
        with open(DIR_NORM + "/" + f, "w") as fd_out:
            data = json.load(fd)
            data['size'] = matrix[i][0]
            data['bb'] = matrix[i][1]
            # data['family'] = matrix[i][2]
            data['call'] = matrix[i][2]
            data['mov'] = matrix[i][3]
            data['push'] = matrix[i][4]
            data['pop'] = matrix[i][5]
            data['add'] = matrix[i][6]
            data['sub'] = matrix[i][7]
            data['xor'] = matrix[i][8]
            data['jmp'] = matrix[i][9]
            json.dump(data, fd_out, indent=4, separators=(',',':'), ensure_ascii=False)

"""
Function that performs the normalization of the features
fd: file descriptotr from open
"""
def normalize():
    global counter
    global matrix

    if DEBUG:
        print "{}".format(DIR)

    start = timeit.default_timer()

    for root, dirs, filenames in os.walk(DIR):
        for f in filter(lambda x:x.endswith(".json"), filenames):
            counter = counter + 1
            loadJSON(f)
            bar.update(counter)

    stop = timeit.default_timer()
    pprint (stop - start)
    print "Start Normalizing"
    matrix = preprocessing.normalize(matrix)
    print "Stop Normalizing"
    i = 0
    for root, dirs, filenames in os.walk(DIR):
        for f in filter(lambda x:x.endswith(".json"), filenames):
            storeJSON(f,i)
            i += 1
            bar.update(counter + i)

    if DEBUG:
        print matrix
        print "Counter = {}".format(counter)

if __name__ == "__main__":
    bar = progressbar.ProgressBar(max_value=21736)
    normalize()
